{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy.spatial.distance import cdist\n",
    "import json\n",
    "import numpy as np\n",
    "import indicoio\n",
    "indicoio.config.api_key = \"cbe0522905613dd0a2c4ff6442355e14\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question Answering\n",
    "\n",
    "def make_feats(data):\n",
    "    \"\"\"\n",
    "    Send our text data throught the indico API and return each text example's text vector representation\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    chunks = [data[x:x+100] for x in range(0, len(data), 100)]\n",
    "    feats = []\n",
    "\n",
    "    # working with chunks of the data at a time\n",
    "    for chunk in chunks:\n",
    "        feats.extend(indicoio.text_features(chunk))\n",
    "\n",
    "    return feats\n",
    "\n",
    "def calculate_distances(feats):\n",
    "    # cosine distance is the most reasonable metric for comparison of these 300d vectors\n",
    "    distances = cdist(feats, feats, 'cosine')\n",
    "    return distances\n",
    "\n",
    "def similarity_text(idx, distance_matrix, data, faqs, n_similar=5):\n",
    "    \"\"\"\n",
    "    idx: the index of the text we're looking for similar questions to\n",
    "         (data[idx] corresponds to the actual text we care about)\n",
    "    distance_matrix: an m by n matrix that stores the distance between\n",
    "                     document m and document n at distance_matrix[m][n]\n",
    "    data: a flat list of text data\n",
    "    \"\"\"\n",
    "\n",
    "    # these are the indexes of the texts that are most similar to the text at data[idx]\n",
    "    # note that this list of 10 elements contains the index of text that we're comparing things to at idx 0\n",
    "    sorted_distance_idxs = np.argsort(distance_matrix[idx])[:n_similar] # EX: [252, 102, 239, ...]\n",
    "    # this is the index of the text that is most similar to the query (index 0)\n",
    "    most_sim_idx = sorted_distance_idxs[1]\n",
    "\n",
    "    # set the variable that will hold our matching FAQ\n",
    "    faq_match = None\n",
    "\n",
    "    for similar_idx in sorted_distance_idxs:\n",
    "        # actual text data for display\n",
    "        datum = data[similar_idx]\n",
    "\n",
    "        # distance in cosine space from our text example to the similar text example\n",
    "        distance = distance_matrix[idx][similar_idx]\n",
    "\n",
    "        # how similar that text data is to our input example\n",
    "        similarity =  1 - distance\n",
    "\n",
    "        # set a confidence threshold\n",
    "        # TODO\n",
    "        if similar_idx == most_sim_idx and similarity >= 0.85:\n",
    "                    faq_match = data[most_sim_idx]\n",
    "        else:\n",
    "            sorry = \"Sorry, I'm not sure how to respond.\"\n",
    "\n",
    "\n",
    "    # print the appropriate answer to the FAQ, or bring in a human to respond\n",
    "    # TODO\n",
    "    if faq_match is not None:\n",
    "            return faqs[faq_match]\n",
    "    else:\n",
    "            return \"Sorry, I'm not sure how to respond.\"\n",
    "        \n",
    "def input_question(question, data, feats):\n",
    "    # TODO\n",
    "    # Pass a question\n",
    "\n",
    "    # add the user question and its vector representations to the corresponding lists, `data` and `feats`\n",
    "    # insert them at index 0 so you know exactly where they are for later distance calculations\n",
    "    if question is not None:\n",
    "        data.insert(0, question)\n",
    "\n",
    "    new_feats = indicoio.text_features(question)\n",
    "    feats.insert(0, new_feats)\n",
    "\n",
    "    return data, feats\n",
    "\n",
    "\n",
    "def answer_question(test_questions_file):\n",
    "    \n",
    "    # reading files and creating dictionary of questions and answers\n",
    "    training_questions_file = open(\"Questions.txt\", \"r\", encoding = \"utf-8\")\n",
    "    training_answers_file = open(\"Answers.txt\", \"r\", encoding = \"utf-8\")\n",
    "    \n",
    "    training_questions = training_questions_file.readlines()\n",
    "    training_answers = training_answers_file.readlines()\n",
    "    \n",
    "    faqs  = dict(zip(training_questions, training_answers))\n",
    "    \n",
    "    # TODO\n",
    "    data = list(faqs.keys()) \n",
    "\n",
    "    feats = make_feats(data)\n",
    "\n",
    "    testing_questions_file = open(test_questions_file, \"r\", encoding = \"utf-8\")\n",
    "    testing_questions = testing_questions_file.readlines()\n",
    "\n",
    "    results_file = open(\"qa_results.txt\", \"wb\")\n",
    "\n",
    "    for question in testing_questions:\n",
    "        \n",
    "        input_results = input_question(question, data, feats)\n",
    "        new_data = input_results[0]\n",
    "        new_feats = input_results[1]\n",
    "        \n",
    "        distance_matrix = calculate_distances(new_feats)\n",
    "        \n",
    "        idx = 0\n",
    "        \n",
    "        answer = similarity_text(idx, distance_matrix, new_data, faqs)\n",
    "        results_file.write(answer.encode(\"utf-8\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic Modelling\n",
    "\n",
    "df_topics = pd.DataFrame()\n",
    "df_topics = pd.read_csv(\"Topics.txt\", delimiter=\"\\t \", engine=\"python\",header=None, names=['topic'])\n",
    "\n",
    "\n",
    "df_questions = pd.DataFrame()\n",
    "df_questions = pd.read_csv(\"Questions.txt\", engine=\"python\", delimiter='\\t',header=None, names=['questions'])\n",
    "\n",
    "\n",
    "topic_model = pd.DataFrame()\n",
    "topic_model = pd.concat([df_questions, df_topics], axis=1)\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", lowercase=\"True\", strip_accents=\"ascii\")\n",
    "\n",
    "y = topic_model.topic\n",
    "X = vectorizer.fit_transform(topic_model.questions.astype('U'))\n",
    "\n",
    "\n",
    "# Importing the function for splitting data into test & train, \n",
    "# as well as F1 metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Splitting the data into 80% training, %20 for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 1)\n",
    "\n",
    "\n",
    "# Importing the logistic regression function\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate the classifier\n",
    "log_reg = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "# The model will learn the relationship between the input \n",
    "# and the observation when fit is called on the data\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Testing the model using the remaining test data\n",
    "lr_predicted = log_reg.predict(X_test)\n",
    "\n",
    "\n",
    "def topic_model(textfile):\n",
    "    test_list = []\n",
    "    infile = open(textfile, \"r\")\n",
    "    \n",
    "    outfile = open(\"topic_results.txt\",\"w\")\n",
    "    for question in infile:\n",
    "        test_list.append(question)\n",
    "        \n",
    "        processed = vectorizer.transform(test_list)\n",
    "        \n",
    "        result = log_reg.predict(processed)\n",
    "        outfile.write(str(result[0]))\n",
    "        outfile.write('\\n')\n",
    "        \n",
    "        test_list = []\n",
    "    infile.close()\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if(len(sys.argv) != 4):\n",
    "    print(\"Check that you have all your arguments\")\n",
    "    \n",
    "    else:\n",
    "        if(sys.argv[1]==\"topic\"):\n",
    "            topic_model(sys.argv[2])\n",
    "            \n",
    "        if(sys.argv[1]==\"qa\"):\n",
    "            answer_question(sys.argv[2])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
